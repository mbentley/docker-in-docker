#!/bin/bash

set -e

# unset DOCKER_HOST, DOCKER_TLS_VERIFY, and DOCKER_CERT_PATH to ensure we are not talking to a machine we shouldn't be
unset DOCKER_HOST DOCKER_TLS_VERIFY DOCKER_CERT_PATH

# Force orchestrator to be Swarm, if Kubernetes is installed on Docker for Mac/Windows
export DOCKER_STACK_ORCHESTRATOR=swarm

# set the script path to allow for an override for a docker plugin
SCRIPT_PATH="${SCRIPT_PATH:-$0}"

initialize() {
  # source an external env var file if DIND_ENV set
  DIND_ENV="${DIND_ENV:-}"
  if [ -n "${DIND_ENV}" ]
  then
    # make sure DIND_ENV is a file
    if [ -f "${DIND_ENV}" ]
    then
      echo -e "Using environment variables from '${DIND_ENV}'\\n"
      #shellcheck disable=SC1090
      source "${DIND_ENV}"
    else
      echo "Warning: DIND_ENV file not found; unable to load environment variables"
      sleep 3
    fi
  fi

  # check to see if ~/dind_docker_enterprise doesn't exist in ~/ddc exists to warn about change
  if [ ! -d "${HOME}/dind_docker_enterprise" ] && [ -d "${HOME}/ddc" ]
  then
    (>&2 echo -e "Warning: using the directory ~/ddc has been deprecated; please rename the directory to ~/dind_docker_enterprise by running:\n  mv ~/ddc ~/dind_docker_enterprise\n")
    sleep 3
  fi

  # set default values; allow for override
  PROJECT="${PROJECT:-dind-docker-enterprise}"
  DIND_TAG="${DIND_TAG:-19.03-ee}"
  ENGINE_ARGS="${ENGINE_ARGS:-}"
  ENGINE_OPTS="${ENGINE_OPTS:-}"
  MANAGERS="${MANAGERS:-1}"
  WORKERS="${WORKERS:-2}"
  UCP_REPO="${UCP_REPO:-docker/ucp}"
  UCP_VERSION="${UCP_VERSION:-3.2.6}"
  UCP_IMAGES="${UCP_IMAGES:-${HOME}/dind_docker_enterprise/ucp_images_"${UCP_VERSION}".tar.gz}"
  UCP_OPTIONS="${UCP_OPTIONS:-}"
  DTR_REPO="${DTR_REPO:-docker/dtr}"
  DTR_VERSION="${DTR_VERSION:-2.7.6}"
  DTR_IMAGES="${DTR_IMAGES:-${HOME}/dind_docker_enterprise/dtr_images_"${DTR_VERSION}".tar.gz}"
  DTR_OPTIONS="${DTR_OPTIONS:-}"
  DTR_REPLICAS="${DTR_REPLICAS:-1}"
  DDC_LICENSE="${DDC_LICENSE:-${HOME}/Downloads/docker_subscription.lic}"
  DIND_SUBNET="${DIND_SUBNET:-172.250.1.0/24}"
  DIND_RESTART="${DIND_RESTART:-no}"
  ALIAS_IP="${ALIAS_IP:-10.1.2.3}"
  DOMAIN_NAME="${DOMAIN_NAME:-demo.mac}"
  GH_USERNAME="${GH_USERNAME:-demo}"

  #  only run a container to get resolv.conf from the engine if DIND_DNS wasn't specified
  if [ -z "${DIND_DNS}" ]
  then
    DIND_DNS="$(docker -H unix:///var/run/docker.sock run --rm busybox cat /etc/resolv.conf | grep -m 1 ^nameserver | awk '{print $2}')"

    # lazy check for ip like string
    if ! [[ ${DIND_DNS} =~ ^[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}$ ]]
    then
      # if all else fails, set the DNS server to google's primary
      echo "Warning: unable to determine DNS server used by host Docker engine; using Google"
      DIND_DNS="8.8.8.8"
    fi
  fi

  # check to see what OS and set network interface
  if [ "$(uname -s)" = "Darwin" ]
  then
     NET_IF="${NET_IF:-en0}"
  else
     NET_IF="${NET_IF:-eth0}"
  fi

  # check for valid number of managers
  if ((MANAGERS<1))
  then
    echo "Error: The number of MANAGERS (${MANAGERS}) must be greater than 0"
    exit 1
  fi

  # check for valid number of workers
  if ((WORKERS<1)) && ((DTR_REPLICAS>0))
  then
    echo "Warning: The number of WORKERS (${WORKERS}) is less than 1; you will not be able to install DTR"
    sleep 2
  fi
}

validate_dtr_replicas() {
  # check for valid number of DTR replicas
  if ((DTR_REPLICAS<1))
  then
    echo "Error: The number of DTR_REPLICAS (${DTR_REPLICAS}) is less than 1; you will not be able to install DTR"
    exit 1
  fi

  if ((DTR_REPLICAS>WORKERS))
  then
    echo "Error: The number of DTR_REPLICAS (${DTR_REPLICAS}) is greater then the number of UCP workers (${WORKERS}); you will not be able to install DTR with the specified number of replicas"
    exit 1
  fi
}

env_info() {
  echo -e "DIND_ENV:\\t${DIND_ENV}"
  echo -e "PROJECT:\\t${PROJECT}"
  echo -e "DIND_TAG:\\t${DIND_TAG}"
  echo -e "ENGINE_ARGS:\\t${ENGINE_ARGS}"
  echo -e "ENGINE_OPTS:\\t${ENGINE_OPTS}"
  echo -e "MANAGERS:\\t${MANAGERS}"
  echo -e "WORKERS:\\t${WORKERS}"
  echo -e "UCP_REPO:\\t${UCP_REPO}"
  echo -e "UCP_VERSION:\\t${UCP_VERSION}"
  echo -e "UCP_IMAGES:\\t${UCP_IMAGES}"
  echo -e "UCP_OPTIONS:\\t${UCP_OPTIONS}"
  echo -e "DTR_REPO:\\t${DTR_REPO}"
  echo -e "DTR_VERSION:\\t${DTR_VERSION}"
  echo -e "DTR_IMAGES:\\t${DTR_IMAGES}"
  echo -e "DDC_LICENSE:\\t${DDC_LICENSE}"
  echo -e "DTR_OPTIONS:\\t${DTR_OPTIONS}"
  echo -e "DTR_REPLICAS:\\t${DTR_REPLICAS}"
  echo -e "DIND_SUBNET:\\t${DIND_SUBNET}"
  echo -e "DIND_DNS:\\t${DIND_DNS}"
  echo -e "DIND_RESTART:\\t${DIND_RESTART}"
  echo -e "NET_IF:\\t\\t${NET_IF}"
  echo -e "ALIAS_IP:\\t${ALIAS_IP}"
  echo -e "DOMAIN_NAME:\\t${DOMAIN_NAME}"
  echo -e "GH_USERNAME:\\t${GH_USERNAME}"
  exit 0
}

check_total_memory() {
  echo "Checking to see if your system meets the system requirements..."
  # run a container to see how much memory is available in the Docker for Mac VM (or standard host OS)
  TOTAL_MEMORY="$(docker -H unix:///var/run/docker.sock run -it --rm busybox cat /proc/meminfo | grep ^MemTotal | awk '{print $2}')"

  # 1 GB recommended per manager
  MANAGER_MEM=1048576

  # 512 MB recommended per worker
  WORKER_MEM=524288

  # Additional memory for registry mirror and HAProxy
  ADDL_MEM=524288

  # calculate the recommended amount of memory
  TTL_MANAGER_MEM="$((MANAGER_MEM * MANAGERS))"
  TTL_WORKER_MEM="$((WORKER_MEM * WORKERS))"
  TTL_MEM_REQ="$((TTL_MANAGER_MEM + TTL_WORKER_MEM + ADDL_MEM))"

  # get some more user friendly numbers
  TTL_MEM_REQ="$((TTL_MEM_REQ / 1024))"
  TOTAL_MEMORY="$((TOTAL_MEMORY / 1024))"

  # check to see if the system has the recommended amount of memory
  if [ "${TOTAL_MEMORY}" -lt "${TTL_MEM_REQ}" ]
  then
    echo "Warning: The amount of memory on your system is less than recommended based off of the number of managers (${MANAGERS}) and workers (${WORKERS}) configured!"
    echo "Your system has a total of ${TOTAL_MEMORY} MB but ${TTL_MEM_REQ} MB is recommended."
    sleep 2
  else
    echo "OK: Your system has a total of ${TOTAL_MEMORY} MB of memory (${TTL_MEM_REQ} MB is the recommended minimum)"
  fi
  echo -e "done.\\n"
}

ddc_check_license() {
  if [ ! -f "${DDC_LICENSE}" ]
  then
    echo "Warning: Unable to find DDC_LICENSE (${DDC_LICENSE}); manually apply a license after installation"
    sleep 5
  else
    echo -e "Found DDC license '${DDC_LICENSE}'\\n"
  fi
}

ucp_check_tar() {
  if [ ! -f "${UCP_IMAGES}" ]
  then
    echo "Error: Unable to find UCP_IMAGES"
    echo "Hint: try running '${SCRIPT_PATH} create_tar ucp' or download an offline tarball to '${UCP_IMAGES}'"
    exit 1
  else
    echo -e "Found UCP tarball '${UCP_IMAGES}'\\n"
  fi
}

dtr_check_tar() {
  if [ ! -f "${DTR_IMAGES}" ]
  then
    echo "Error: Unable to find DTR_IMAGES"
    echo "Hint: try running '${SCRIPT_PATH} create_tar dtr' or download an offline tarball to '${DTR_IMAGES}'"
    exit 1
  else
    echo -e "Found DTR tarball '${DTR_IMAGES}'\\n"
  fi
}

ucp_create_tar() {
  UCP_IMAGES_DIR="$(dirname "${UCP_IMAGES}")"
  if [ ! -d "${UCP_IMAGES_DIR}" ]
  then
    echo "Creating directory ${UCP_IMAGES_DIR}..."
    mkdir -p "${UCP_IMAGES_DIR}"
  fi

  if [ ! -f "${UCP_IMAGES}" ]
  then
    echo "Creating tarball of UCP images..."
    #shellcheck disable=SC2086 disable=SC2046
    {
      docker -H unix:///var/run/docker.sock run --rm "${UCP_REPO}":"${UCP_VERSION}" images --list ${UCP_OPTIONS} | xargs -L 1 docker -H unix:///var/run/docker.sock pull
      docker -H unix:///var/run/docker.sock save -o "${UCP_IMAGES}" $(docker -H unix:///var/run/docker.sock run --rm "${UCP_REPO}":"${UCP_VERSION}" images --list ${UCP_OPTIONS}) "${UCP_REPO}":"${UCP_VERSION}"
      docker -H unix:///var/run/docker.sock rmi $(docker -H unix:///var/run/docker.sock run --rm "${UCP_REPO}":"${UCP_VERSION}" images --list ${UCP_OPTIONS}) "${UCP_REPO}":"${UCP_VERSION}" || true
    }
    echo -e "done.\\n"
  else
    echo "Error: Tarball of UCP images (${UCP_IMAGES}) already exists.  If you want to create a new tarball, please remove this file first"
    exit 1
  fi
}

dtr_create_tar() {
  DTR_IMAGES_DIR="$(dirname "${DTR_IMAGES}")"
  if [ ! -d "${DTR_IMAGES_DIR}" ]
  then
    echo "Creating directory ${DTR_IMAGES_DIR}..."
    mkdir -p "${DTR_IMAGES_DIR}"
  fi

  if [ ! -f "${DTR_IMAGES}" ]
  then
    echo "Creating tarball of DTR images..."
    #shellcheck disable=SC2046
    {
      docker -H unix:///var/run/docker.sock run --rm "${DTR_REPO}":"${DTR_VERSION}" images | xargs -L 1 docker -H unix:///var/run/docker.sock pull
      docker -H unix:///var/run/docker.sock save -o "${DTR_IMAGES}" $(docker -H unix:///var/run/docker.sock run --rm "${DTR_REPO}":"${DTR_VERSION}" images)
      docker -H unix:///var/run/docker.sock rmi $(docker -H unix:///var/run/docker.sock run --rm "${DTR_REPO}":"${DTR_VERSION}" images)
    }
    echo -e "done.\\n"
  else
    echo "Error: Tarball of DTR images (${DTR_IMAGES}) already exists.  If you want to create a new tarball, please remove this file first"
    exit 1
  fi
}

create_net_alias() {
  # run this only on a mac
  if [ "$(uname -s)" = "Darwin" ]
  then
    # check to see if the alias IP is already set
    if ! ifconfig "${NET_IF}" | grep "${ALIAS_IP}" > /dev/null 2>&1
    then
      # create it
      echo "Creating IP alias (requires sudo)..."
      sudo ifconfig "${NET_IF}" alias "${ALIAS_IP}" netmask 255.255.255.255
      echo -e "done.\\n"
    else
      # skip creation; already exists
      echo "IP alias (${ALIAS_IP}) already exists"
      echo -e "done.\\n"
    fi
  else
    echo "Skipping creation of network IP alias; you're not on a Mac"

    # check to see if the default ALIAS_IP is set
    if [ "${ALIAS_IP}" = "10.1.2.3" ]
    then
      echo "ERROR: ALIAS_IP is not set; set to your host's IP address or installations will fail"
      exit 1
    fi
    echo -e "done.\\n"
  fi
}

remove_net_alias() {
  # run this only on a mac
  if [ "$(uname -s)" = "Darwin" ]
  then
    # check to see if the default ALIAS_IP is set
    if [ "${ALIAS_IP}" = "10.1.2.3" ]
    then
      # check to see if the alias IP is already set
      if ifconfig "${NET_IF}" | grep "${ALIAS_IP}" > /dev/null 2>&1
      then
        # remove it
        echo "Removing IP alias (requires sudo)..."
        sudo ifconfig "${NET_IF}" -alias "${ALIAS_IP}" 255.255.255.0
        echo -e "done.\\n"
      else
        # skip creation; already exists
        echo "IP alias (${ALIAS_IP}) does not exist; skipping removal..."
        echo -e "done.\\n"
      fi
    else
      # skip because custom address provided
      echo "Skipping removal of network IP alias; custom address provided..."
      echo -e "done.\\n"
    fi
  else
    echo "Skipping removal of network IP alias; you're not on a Mac..."
    echo -e "done.\\n"
  fi
}

recreate_net_alias() {
  echo "Checking to see if network alias is functional..."
  MIRROR_STATUS="$(curl -m 5 -s -o /dev/null -w "%{http_code}" "http://${ALIAS_IP}:5000/" || true)"
  if [ "${MIRROR_STATUS}" = "200" ]
  then
    echo -e "Connection test successful; skipping network alias re-creation...\\ndone.\\n"
  else
    echo "Connection test to the registry mirror failed; re-creating network alias..."
    remove_net_alias
    create_net_alias
  fi
}

check_other_projects() {
  if [ "$(docker -H unix:///var/run/docker.sock ps -a -f label=project -q | wc -l | tr -d ' ')" -ne "0" ]
  then
    # return true (other projects exist)
    echo "1"
  else
    # return false (no other projects exist)
    echo "0"
  fi
}

create_swarm() {
  launch_engines
  init_swarm
}

launch_engines() {
  # create dind network
  echo "Checking for subnet availability..."
  check_subnet
  echo -e "done.\\n"

  # create network, if necessary
  create_network

  # get subnet prefix
  DIND_SUBNET_PREFIX="$(docker -H unix:///var/run/docker.sock network inspect --format '{{range .IPAM.Config}}{{.Subnet}}{{end}}' "${PROJECT}"-dind | awk -F '/' '{print $1}' | awk -F '.' '{print $1"."$2"."$3"."}')"

  NUM_NODES=$((MANAGERS+WORKERS))

  echo "Creating volumes for Docker engines..."
  for ((ENGINE_NUM=1; ENGINE_NUM<=NUM_NODES; ENGINE_NUM++))
  do
    VOLUME_PATHS="/etc/docker /etc/cni /opt/cni /opt/containerd /var/lib/cni /var/lib/containerd /var/lib/docker /var/lib/dockershim /var/lib/kubelet /usr/libexec/kubernetes /var/log"
    for VOLUME_PATH in ${VOLUME_PATHS}
    do
      if [ "$(docker -H unix:///var/run/docker.sock volume ls -q --filter name="${PROJECT}-docker${ENGINE_NUM}${VOLUME_PATH//\//-}" | grep -w "${PROJECT}-docker${ENGINE_NUM}${VOLUME_PATH//\//-}")" = "${PROJECT}-docker${ENGINE_NUM}${VOLUME_PATH//\//-}" ]
      then
        echo "Volume (${PROJECT}-docker${ENGINE_NUM}${VOLUME_PATH//\//-}) already exists; skipping creation."
      else
        docker -H unix:///var/run/docker.sock volume create \
          --label project="${PROJECT}" \
          --driver local \
          "${PROJECT}-docker${ENGINE_NUM}${VOLUME_PATH//\//-}"
      fi
    done
  done

  if [ "$(docker -H unix:///var/run/docker.sock volume ls -q --filter name="${PROJECT}-shared" | grep -w "${PROJECT}-shared")" = "${PROJECT}-shared" ]
  then
    echo "Volume (${PROJECT}-shared) already exists; skipping creation."
  else
    docker -H unix:///var/run/docker.sock volume create \
      --label project="${PROJECT}" \
      --driver local \
      "${PROJECT}"-shared
  fi
  echo -e "done.\\n"

  if [ "${1}" = "engineonly" ]
  then
    echo "Creating ${MANAGERS} Docker engines..."
  else
    echo "Creating ${MANAGERS} Docker engines for Swarm managers..."
  fi
  # launch all managers
  for ((ENGINE_NUM=1; ENGINE_NUM<=MANAGERS; ENGINE_NUM++))
  do
    #shellcheck disable=SC2086
    {
      docker -H unix:///var/run/docker.sock create \
        -p 127.0.0.1:100${ENGINE_NUM}:12375 \
        --name "${PROJECT}"-docker${ENGINE_NUM} \
        --hostname "${PROJECT}"-docker${ENGINE_NUM} \
        --label project="${PROJECT}" \
        --label role=manager \
        --privileged \
        --net "${PROJECT}"-dind \
        --ip "${DIND_SUBNET_PREFIX}"$((ENGINE_NUM+51)) \
        --restart "${DIND_RESTART}" \
        -v /lib/modules:/lib/modules:ro \
        -v "${PROJECT}"-docker${ENGINE_NUM}-etc-docker:/etc/docker \
        -v "${PROJECT}"-docker${ENGINE_NUM}-etc-cni:/etc/cni \
        -v "${PROJECT}"-docker${ENGINE_NUM}-opt-cni:/opt/cni \
        -v "${PROJECT}"-docker${ENGINE_NUM}-opt-containerd:/opt/containerd \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-lib-cni:/var/lib/cni \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-lib-containerd:/var/lib/containerd \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-lib-docker:/var/lib/docker \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-lib-dockershim:/var/lib/dockershim \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-lib-kubelet:/var/lib/kubelet \
        -v "${PROJECT}"-docker${ENGINE_NUM}-usr-libexec-kubernetes:/usr/libexec/kubernetes \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-log:/var/log \
        -v "${PROJECT}"-shared:/data \
        -v "${PROJECT}"-shared:/shared \
        ${ENGINE_ARGS} \
        --tmpfs /run \
        -e MOUNT_PROPAGATION="/" \
        mbentley/docker-in-docker:"${DIND_TAG}" \
        dockerd -s overlay2 \
          -H unix:///var/run/docker.sock -H tcp://0.0.0.0:12375 \
          --log-driver json-file --log-opt max-size=50m --log-opt max-file=3 \
          --dns "${DIND_DNS}" \
          --registry-mirror http://"${PROJECT}"-mirror:5000 \
          ${ENGINE_OPTS} > /dev/null

      # check to see if we should start the newly created engine
      if [ "${WAS_RUNNING}" != "false" ]
      then
        echo -n "Starting ${PROJECT}-docker${ENGINE_NUM}..."
        docker -H unix:///var/run/docker.sock start "${PROJECT}"-docker${ENGINE_NUM} > /dev/null
        echo "done"
      fi
     }
  done
  echo -e "done.\\n"

  if [ "${1}" = "engineonly" ]
  then
    echo "Creating ${WORKERS} Docker engines..."
  else
    echo "Creating ${WORKERS} Docker engines for Swarm workers..."
  fi
  # launch all workers
  for ((ENGINE_NUM=((MANAGERS+1)); ENGINE_NUM<=((NUM_NODES)); ENGINE_NUM++))
  do
    #shellcheck disable=SC2086
    {
      docker -H unix:///var/run/docker.sock create \
        -p 127.0.0.1:100${ENGINE_NUM}:12375 \
        --name "${PROJECT}"-docker${ENGINE_NUM} \
        --hostname "${PROJECT}"-docker${ENGINE_NUM} \
        --label project="${PROJECT}" \
        --label role=worker \
        --privileged \
        --net "${PROJECT}"-dind \
        --ip "${DIND_SUBNET_PREFIX}"$((ENGINE_NUM+51)) \
        --restart "${DIND_RESTART}" \
        -v /lib/modules:/lib/modules:ro \
        -v "${PROJECT}"-docker${ENGINE_NUM}-etc-docker:/etc/docker \
        -v "${PROJECT}"-docker${ENGINE_NUM}-etc-cni:/etc/cni \
        -v "${PROJECT}"-docker${ENGINE_NUM}-opt-cni:/opt/cni \
        -v "${PROJECT}"-docker${ENGINE_NUM}-opt-containerd:/opt/containerd \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-lib-cni:/var/lib/cni \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-lib-containerd:/var/lib/containerd \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-lib-docker:/var/lib/docker \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-lib-dockershim:/var/lib/dockershim \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-lib-kubelet:/var/lib/kubelet \
        -v "${PROJECT}"-docker${ENGINE_NUM}-usr-libexec-kubernetes:/usr/libexec/kubernetes \
        -v "${PROJECT}"-docker${ENGINE_NUM}-var-log:/var/log \
        -v "${PROJECT}"-shared:/shared \
        -v "${PROJECT}"-shared:/data \
        ${ENGINE_ARGS} \
        --tmpfs /run \
        -e MOUNT_PROPAGATION="/" \
        mbentley/docker-in-docker:"${DIND_TAG}" \
        dockerd -s overlay2 \
          -H unix:///var/run/docker.sock -H tcp://0.0.0.0:12375 \
          --log-driver json-file --log-opt max-size=50m --log-opt max-file=3 \
          --dns "${DIND_DNS}" \
          --registry-mirror http://"${PROJECT}"-mirror:5000 \
          ${ENGINE_OPTS} > /dev/null

      # check to see if we should start the newly created engine
      if [ "${WAS_RUNNING}" != "false" ]
      then
        echo -n "Starting ${PROJECT}-docker${ENGINE_NUM}..."
        docker -H unix:///var/run/docker.sock start "${PROJECT}"-docker${ENGINE_NUM} > /dev/null
        echo "done"
      fi
     }
  done
  echo -e "done.\\n"

  echo "Creating volume for registry mirror cache..."
  if [ "$(docker -H unix:///var/run/docker.sock volume ls -q --filter name="shared-mirror-cache" | grep -w "shared-mirror-cache")" = "shared-mirror-cache" ]
  then
    echo "Volume (shared-mirror-cache) already exists; skipping creation."
  else
    docker -H unix:///var/run/docker.sock volume create \
      --driver local \
      shared-mirror-cache
  fi
  echo -e "done.\\n"

  echo "Creating registry mirror for Docker engines..."
  docker -H unix:///var/run/docker.sock create \
    -p 5000:5000 \
    --name "${PROJECT}"-mirror \
    --hostname "${PROJECT}"-mirror \
    --label project="${PROJECT}" \
    --net "${PROJECT}"-dind \
    --restart "${DIND_RESTART}" \
    -v shared-mirror-cache:/var/lib/registry \
    mbentley/docker-in-docker:mirror > /dev/null

  if [ "${WAS_RUNNING}" != "false" ]
  then
    echo -n "Starting ${PROJECT}-mirror..."
    docker -H unix:///var/run/docker.sock start "${PROJECT}"-mirror > /dev/null
    echo "done"
  fi
  echo -e "done.\\n"
}

get_container_list() {
  docker -H unix:///var/run/docker.sock ps -a --filter label=project="${PROJECT}" --format '{{.Names}}'
}

get_volume_list() {
  docker -H unix:///var/run/docker.sock volume ls --filter label=project="${PROJECT}" --format '{{.Name}}'
}

get_network_list() {
  docker -H unix:///var/run/docker.sock network ls --filter label=project="${PROJECT}" --format '{{.Name}}'
}

check_running_containers() {
  # get a list of running containers for project
  RUNNING_CONTAINERS="$(curl -s -G -XGET --unix-socket /var/run/docker.sock -d "all=1" --data-urlencode 'filters={"status":["running"],"label":["project='"${PROJECT}"'"]}' "http:/v1.24/containers/json")"

  # check to see if there were any running containers for the project
  if [ "${RUNNING_CONTAINERS}" != "[]" ]
  then
    # running containers found; assume running
    echo "true"
  else
    # no running containers found; assume to be not running
    echo "false"
  fi
}

start_containers() {
  # create network, if necessary
  create_network

  CONTAINERS="$(get_container_list)"
  if [ -z "${CONTAINERS}" ]
  then
    echo "No project containers found; skipping..."
  else
    echo "Starting project containers..."
    #shellcheck disable=SC2046
    docker -H unix:///var/run/docker.sock start $(get_container_list) || true
  fi
  echo -e "done.\\n"
}

stop_containers() {
  CONTAINERS="$(get_container_list)"
  if [ -z "${CONTAINERS}" ]
  then
    echo "No project containers found; skipping..."
  else
    echo "Stopping project containers; this may take up to 30 seconds..."
    #shellcheck disable=SC2086
    docker -H unix:///var/run/docker.sock stop -t 30 ${CONTAINERS} || true
  fi
  echo -e "done.\\n"
}

pause_containers() {
  CONTAINERS="$(get_container_list)"
  if [ -z "${CONTAINERS}" ]
  then
    echo "No project containers found; skipping..."
  else
    echo "Pausing project containers..."
    #shellcheck disable=SC2086
    docker -H unix:///var/run/docker.sock pause ${CONTAINERS} || true
  fi
  echo -e "done.\\n"
}

unpause_containers() {
  CONTAINERS="$(get_container_list)"
  if [ -z "${CONTAINERS}" ]
  then
    echo "No project containers found; skipping..."
  else
    echo "Unpausing project containers..."
    #shellcheck disable=SC2086
    docker -H unix:///var/run/docker.sock unpause ${CONTAINERS} || true
  fi
  echo -e "done.\\n"
}

recycle_containers() {
  # check to see if an environment file was provided; if so, use that because it is more trustworth on counting the number of engines
  if [ -z "${DIND_ENV}" ]
  then
    # can't guarantee how many engines we might have; count the number of existing containers
    get_current_num_engines
  fi

  # check to see if any of the project containers are currently running
  WAS_RUNNING="$(check_running_containers)"

  # check to see if the ddc-lb exists
  if [ "$(docker -H unix:///var/run/docker.sock ps -a --filter label=project="${PROJECT}" --format '{{.Names}}' --filter name="${PROJECT}"-ddc-lb)" == "${PROJECT}-ddc-lb" ]
  then
    RECREATE_LB=true
  else
    RECREATE_LB=false
  fi

  stop_containers

  CONTAINERS="$(get_container_list)"
  if [ -z "${CONTAINERS}" ]
  then
    echo "No project containers to remove; skipping..."
  else
  echo "Removing project containers..."
    #shellcheck disable=SC2086
    docker -H unix:///var/run/docker.sock rm ${CONTAINERS}
  fi
  echo -e "done.\\n"

  NETWORKS="$(get_network_list)"
  if [ -z "${NETWORKS}" ]
  then
    echo "No project networks to remove; skipping..."
  else
  echo "Removing '${PROJECT}-dind' network..."
    #shellcheck disable=SC2086
    docker -H unix:///var/run/docker.sock network rm ${NETWORKS}
  fi
  echo -e "done.\\n"

  launch_engines
  if [ "${RECREATE_LB}" = "true" ]
  then
    launch_haproxy
  fi
}

project_status() {
  PROJECT_LIST="$(docker -H unix:///var/run/docker.sock ps -a --format '{{.Label "project"}}' | uniq | sort)"
  PROJECT_LIST_RUNNING="$(docker -H unix:///var/run/docker.sock ps --format '{{.Label "project"}}' | uniq | sort)"
  echo -n "All projects found (* = running): "
  for i in ${PROJECT_LIST}
  do
    if [ "${PROJECT_LIST_RUNNING}" = "${i}" ]
    then
      echo -n "${i}* "
    else
      echo -n "${i} "
    fi
  done
  echo -e "\\n"

  # if a project specified, use that
  if [ -n "${1}" ]
  then
    PROJECT="${1}"
  fi

  echo "Containers for current project '${PROJECT}':"
  docker -H unix:///var/run/docker.sock ps -a --filter label=project="${PROJECT}" --format 'table {{.ID}}\t{{.Image}}\t{{.Status}}\t{{.Names}}\t{{.Labels}}'

  echo -e "\\nVolumes for current project '${PROJECT}':"
  docker -H unix:///var/run/docker.sock volume ls --filter label=project="${PROJECT}"

  echo -e "\\nNetworks for current project '${PROJECT}':"
  docker -H unix:///var/run/docker.sock network ls --filter label=project="${PROJECT}"
}

get_current_num_engines() {
  # count the number of existing containers
  MANAGERS="$(docker -H unix:///var/run/docker.sock ps -a --filter label=project="${PROJECT}" --filter label=role=manager --filter name=docker --format '{{.Names}}' | wc -l | tr -d ' ')"
  WORKERS="$(docker -H unix:///var/run/docker.sock ps -a --filter label=project="${PROJECT}" --filter label=role=worker --filter name=docker --format '{{.Names}}' | wc -l | tr -d ' ')"

  # validate the results we received
  case ${MANAGERS} in
    ''|*[!0-9]*)
      echo "Error: The number of MANAGERS (${MANAGERS}) returned was not a number"
      exit 1
      ;;
  esac

  case ${WORKERS} in
    ''|*[!0-9]*)
      echo "Error: The number of WORKERS (${WORKERS}) returned was not a number"
      exit 1
      ;;
  esac
}

init_swarm() {
  # make sure engine is ready
  while ! docker -H tcp://127.0.0.1:1001 version > /dev/null 2>&1
  do
    sleep .1
  done

  echo "Initializing Swarm on ${PROJECT}-docker1..."
  docker -H tcp://127.0.0.1:1001 swarm init
  echo -e "done.\\n"

  # get swarm manager join token
  MANAGER_TOKEN=$(docker -H tcp://127.0.0.1:1001 swarm join-token manager -q)

  # get swarm worker join token
  WORKER_TOKEN=$(docker -H tcp://127.0.0.1:1001 swarm join-token worker -q)

  MANAGER_JOIN_COMMAND="swarm join --token ${MANAGER_TOKEN} $(docker -H unix:///var/run/docker.sock container inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' "${PROJECT}"-docker1):2377"

  WORKER_JOIN_COMMAND="swarm join --token ${WORKER_TOKEN} $(docker -H unix:///var/run/docker.sock container inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' "${PROJECT}"-docker1):2377"

  # join managers
  for ((ENGINE_NUM=2; ENGINE_NUM<=MANAGERS; ENGINE_NUM++))
  do
    # make sure engine is ready
    while ! docker -H tcp://127.0.0.1:100${ENGINE_NUM} version > /dev/null 2>&1
    do
      sleep .1
    done

    echo "Joining ${PROJECT}-docker${ENGINE_NUM} to the Swarm..."
    #shellcheck disable=SC2086
    docker -H tcp://127.0.0.1:100${ENGINE_NUM} ${MANAGER_JOIN_COMMAND}
    echo -e "done.\\n"
  done

  # join workers
  for ((ENGINE_NUM=((MANAGERS+1)); ENGINE_NUM<=((MANAGERS+WORKERS)); ENGINE_NUM++))
  do
    # make sure engine is ready
    while ! docker -H tcp://127.0.0.1:100${ENGINE_NUM} version > /dev/null 2>&1
    do
      sleep .1
    done

    echo "Joining ${PROJECT}-docker${ENGINE_NUM} to the Swarm..."
    #shellcheck disable=SC2086
    docker -H tcp://127.0.0.1:100${ENGINE_NUM} ${WORKER_JOIN_COMMAND}
    echo -e "done.\\n"
  done

  # output node info
  echo -e "Swarm setup complete.\\n"
}

connect_engine() {
  ENGINE_NUM="$(echo "${1}" | grep -o '[0-9]\+')"
  echo "# to connect to a given engine, use:"
  #shellcheck disable=SC2016
  echo '# eval "$('"${SCRIPT_PATH}"' connect_engine '"${1}"')"'
  echo 'unset DOCKER_HOST DOCKER_TLS_VERIFY DOCKER_CERT_PATH'
  echo "export DOCKER_HOST=tcp://127.0.0.1:100${ENGINE_NUM}"
}

install_ucp() {
  echo -e "Preparing cluster for UCP installation...\\n"

  # check to see if an environment file was provided; if so, use that because it is more trustworth on counting the number of engines
  if [ -z "${DIND_ENV}" ]
  then
    # can't guarantee how many engines we might have; count the number of existing containers
    get_current_num_engines
  fi

  # create network alias
  create_net_alias

  # make sure hosts file has correct entries written to it
  write_hosts

  # get IP of the first container
  DOCKER1_IP="$(docker -H unix:///var/run/docker.sock container inspect --format='{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' "${PROJECT}"-docker1)"

  # load images on managers
  for ((ENGINE_NUM=1; ENGINE_NUM<=MANAGERS; ENGINE_NUM++))
  do
    echo "Loading UCP images for managers on ${PROJECT}-docker${ENGINE_NUM}..."
    #shellcheck disable=SC2086
    docker -H tcp://127.0.0.1:100${ENGINE_NUM} load -i "${UCP_IMAGES}"
    echo -e "done.\\n"
  done

  # load images on workers
  for ((ENGINE_NUM=((MANAGERS+1)); ENGINE_NUM<=((MANAGERS+WORKERS)); ENGINE_NUM++))
  do
    echo "Loading UCP images for workers on ${PROJECT}-docker${ENGINE_NUM}..."
    # load only necessary images for UCP 2.0; load all for everything else
    if [ "$(echo "${UCP_VERSION}" | awk -F '.' '{print $1}')" == "2" ]
    then
      # only load necessary images from the primary manager
      docker -H tcp://127.0.0.1:1001 save "${UCP_REPO}"-agent:"${UCP_VERSION}" | docker -H tcp://127.0.0.1:100${ENGINE_NUM} load || true
      docker -H tcp://127.0.0.1:1001 save "${UCP_REPO}"-dsinfo:"${UCP_VERSION}" | docker -H tcp://127.0.0.1:100${ENGINE_NUM} load || true
      docker -H tcp://127.0.0.1:1001 save "${UCP_REPO}"-hrm:"${UCP_VERSION}" | docker -H tcp://127.0.0.1:100${ENGINE_NUM} load || true
    else
      # load all images for anything not UCP 2.x
      docker -H tcp://127.0.0.1:100${ENGINE_NUM} load -i "${UCP_IMAGES}"
    fi
    echo -e "done.\\n"
  done

  # launch haproxy
  launch_haproxy

  # break out UCP version to major, minor, and patch
  UCP_MAJ_VER="$(echo "${UCP_VERSION}" | awk -F '.' '{print $1}')"
  UCP_MIN_VER="$(echo "${UCP_VERSION}" | awk -F '.' '{print $2}')"
  UCP_PAT_VER="$(echo "${UCP_VERSION}" | awk -F '.' '{print $3}' | awk -F '-' '{print $1}')"

  # create custom config and set the `--existing-config` option if UCP verison is greater than 3.1.1 but less than 3.3.0
  if { { [ "${UCP_MAJ_VER}" -eq "3" ] && [ "${UCP_MIN_VER}" -ge "1" ] && [ "${UCP_PAT_VER}" -ge "2" ]; } || { [ "${UCP_MAJ_VER}" -eq "3" ] && [ "${UCP_MIN_VER}" -ge "2" ]; } } && { [ "${UCP_MAJ_VER}" -eq "3" ] && [ "${UCP_MIN_VER}" -le "2" ]; }
  then
    echo -e '[cluster_config]\n  custom_kubelet_flags = ["--http-check-frequency=20s", "--containerized=false"]' | docker -H tcp://127.0.0.1:1001 config create com.docker.ucp.config -
    UCP_OPTIONS="${UCP_OPTIONS} --existing-config"
  fi

  echo "Installing UCP on ${PROJECT}-docker1..."
  #shellcheck disable=SC2086
  docker -H tcp://127.0.0.1:1001 run -it --rm --name ucp -v /var/run/docker.sock:/var/run/docker.sock "${UCP_REPO}":"${UCP_VERSION}" install ${UCP_OPTIONS} --admin-username admin --admin-password docker123 --host-address "${DOCKER1_IP}" --controller-port 443 --disable-tracking --disable-usage --san ucp.${DOMAIN_NAME} --san "${DOCKER1_IP}" --san "${ALIAS_IP}" --san "$(hostname)" --san "$(hostname -f)" --license "$(cat ${DDC_LICENSE})"
  echo -e "done.\\n"

  # delete custom config if UCP verison is greater than 3.1.1 but less than 3.3.0
  if { { [ "${UCP_MAJ_VER}" -eq "3" ] && [ "${UCP_MIN_VER}" -ge "1" ] && [ "${UCP_PAT_VER}" -ge "2" ]; } || { [ "${UCP_MAJ_VER}" -eq "3" ] && [ "${UCP_MIN_VER}" -ge "2" ]; } } && { [ "${UCP_MAJ_VER}" -eq "3" ] && [ "${UCP_MIN_VER}" -le "2" ]; }
  then
    docker -H tcp://127.0.0.1:1001 config rm com.docker.ucp.config
  fi

  # add the ALIAS_IP to the SANs engine labels of the managers
  for ((ENGINE_NUM=2; ENGINE_NUM<=MANAGERS; ENGINE_NUM++))
  do
    echo "Adding UCP node label for SANs..."
    docker -H tcp://127.0.0.1:1001 node update --label-add "com.docker.ucp.SANs=$(docker -H tcp://127.0.0.1:1001 node inspect --format '{{(index .Spec.Labels "com.docker.ucp.SANs")}}' "${PROJECT}"-docker${ENGINE_NUM}),${ALIAS_IP},ucp.${DOMAIN_NAME}" "${PROJECT}"-docker${ENGINE_NUM}
    echo -e "done.\\n"
  done

  # check for jq and then setup HRM
  if hash jq 2>/dev/null
  then
    echo -e "'jq' found; using native binary\\n"
    JQ="jq"
  else
    echo -e "'jq' not found; using Docker image mbentley/jq\\n"
    JQ="docker -H unix:///var/run/docker.sock run -i --rm mbentley/jq"
  fi

  echo -n "Waiting for UCP to be ready..."
  #shellcheck disable=SC2016
  docker -H unix:///var/run/docker.sock run -i --rm -e DOMAIN_NAME="${DOMAIN_NAME}" --entrypoint sh mbentley/curl -c 'while [ "$(curl -sk -o /dev/null -w "%{http_code}" "https://ucp.${DOMAIN_NAME}/_ping")" -ne "200" ]; do   echo -n ".";   sleep 1; done'
  echo -e "done.\\n\\n"

  # get auth token
  AUTH_TOKEN="$(docker -H unix:///var/run/docker.sock run -i --rm mbentley/curl -sk -d '{"username":"admin","password":"docker123"}' "https://ucp.${DOMAIN_NAME}/auth/login" | ${JQ} -r .auth_token 2>/dev/null)"

  if [ "$(echo "${UCP_VERSION}" | awk -F '.' '{print $1}')" == "2" ]
  then
    echo "Enabling HRM..."
    docker -H unix:///var/run/docker.sock run -i --rm mbentley/curl -sk -X POST -H "Authorization: Bearer ${AUTH_TOKEN}" --header "Content-Type: application/json" --header "Accept: application/json" -d '{"HTTPPort":8080,"HTTPSPort":8443}' "https://ucp.${DOMAIN_NAME}/api/hrm"
    echo -e "done.\\n"
  else
    echo "Enabling Interlock..."
    docker -H unix:///var/run/docker.sock run -i --rm mbentley/curl -sk -X POST -H "Authorization: Bearer ${AUTH_TOKEN}" --header "Content-Type: application/json" --header "Accept: application/json" -d '{"HTTPPort":8080,"HTTPSPort":8443,"Arch":"x86_64"}' "https://ucp.${DOMAIN_NAME}/api/interlock"
    echo -e "done.\\n"

    echo "Enabling Kubernetes Ingress..."
    # Get script path
    # test to see if script executed from symlink
    if [ -L "${0}" ]
    then
      # resolve the symlink to the actual path
      SCRIPT_PATH="$(dirname "$(readlink "${0}")")"
    else
      # cd to the path to get the full pwd
      SCRIPT_PATH="$(cd "$(dirname "${0}")" && pwd)"
    fi

    # Create namespace
    docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/api/v1/namespaces" -XPOST -H 'Content-Type: application/json' -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/namespace.json

    # check UCP version
    if { [ "$(echo "${UCP_VERSION}" | awk -F '.' '{print $1}')" -eq "3" ] && [ "$(echo "${UCP_VERSION}" | awk -F '.' '{print $2}')" -ge "1" ]; } || { [ "$(echo "${UCP_VERSION}" | awk -F '.' '{print $1}')" -eq "3" ] && [ "$(echo "${UCP_VERSION}" | awk -F '.' '{print $2}')" -ge "2" ]; } || { [ "$(echo "${UCP_VERSION}" | awk -F '.' '{print $1}')" -ge "4" ]; }
    then
      # UCP 3.1.x or higher
      # add k8s rbac for nginx-ingress
      docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/api/v1/namespaces/ingress-nginx/serviceaccounts" -XPOST -H 'Content-Type: application/json' -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/rbac-serviceaccount.json
      docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/apis/rbac.authorization.k8s.io/v1beta1/clusterroles/nginx-ingress-clusterrole" -XPUT -H "Content-Type: application/json" -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/rbac-clusterrole.json
      docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/apis/rbac.authorization.k8s.io/v1beta1/namespaces/ingress-nginx/roles" -XPOST -H 'Content-Type: application/json' -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/rbac-role.json
      docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/apis/rbac.authorization.k8s.io/v1beta1/namespaces/ingress-nginx/rolebindings" -XPOST -H 'Content-Type: application/json' -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/rbac-rolebinding.json
      docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/apis/rbac.authorization.k8s.io/v1beta1/clusterrolebindings/nginx-ingress-clusterrole-nisa-binding" -XPUT -H "Content-Type: application/json" -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/rbac-clusterrolebinding.json
    else
      # UCP 3.0.x
      # Add grant
      docker -H unix:///var/run/docker.sock run -i --rm mbentley/curl -sk -X PUT -H "Authorization: Bearer ${AUTH_TOKEN}" "https://ucp.${DOMAIN_NAME}/collectionGrants/system%3Aserviceaccount%3Aingress-nginx%3Adefault/kubernetesnamespaces/restrictedcontrol?type=grantobject"
    fi

    docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/api/v1/namespaces/ingress-nginx/configmaps" -XPOST -H 'Content-Type: application/json' -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/configmap.json
    docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/api/v1/namespaces/ingress-nginx/configmaps" -XPOST -H 'Content-Type: application/json' -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/tcp-services-configmap.json
    docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/api/v1/namespaces/ingress-nginx/configmaps" -XPOST -H 'Content-Type: application/json' -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/udp-services-configmap.json
    docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/apis/apps/v1beta1/namespaces/ingress-nginx/deployments" -XPOST -H 'Content-Type: application/json' -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/default-backend-deploy.json
    docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/apis/apps/v1beta1/namespaces/ingress-nginx/deployments" -XPOST -H 'Content-Type: application/json' -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/ingress-deploy.json
    docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/api/v1/namespaces/ingress-nginx/services" -XPOST -H 'Content-Type: application/json' -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/default-backend-service.json
    docker -H unix:///var/run/docker.sock run -i --rm -v "${SCRIPT_PATH}"/json:/json mbentley/curl -sk "https://ucp.${DOMAIN_NAME}/api/v1/namespaces/ingress-nginx/services" -XPOST -H 'Content-Type: application/json' -H "Authorization: Bearer ${AUTH_TOKEN}" -d@/json/ingress-service.json
    echo -e "done.\\n"
  fi



  echo "Creating 'demo' user with password 'docker123'..."
  docker -H unix:///var/run/docker.sock run -i --rm mbentley/curl -sk -X POST -H "Authorization: Bearer ${AUTH_TOKEN}" --header "Content-Type: application/json" --header "Accept: application/json" -d '{"name":"demo","password":"docker123","fullName":"Demo User","isAdmin":true,"isActive":true}' "https://ucp.${DOMAIN_NAME}/accounts/"
  echo -e "done.\\n"

  echo -e "UCP installation complete.\\n"
}

launch_haproxy() {
  # get subnet prefix
  DIND_SUBNET_PREFIX="$(docker -H unix:///var/run/docker.sock network inspect --format '{{range .IPAM.Config}}{{.Subnet}}{{end}}' "${PROJECT}"-dind | awk -F '/' '{print $1}' | awk -F '.' '{print $1"."$2"."$3"."}')"

  echo "Creating HAProxy (${PROJECT}-ddc-lb)..."
  docker -H unix:///var/run/docker.sock create \
    -p 80:80 \
    -p 443:443 \
    -p 6443:6443 \
    --name "${PROJECT}"-ddc-lb \
    --label project="${PROJECT}" \
    --net "${PROJECT}"-dind \
    --ip "${DIND_SUBNET_PREFIX}"$((MANAGERS+WORKERS+52)) \
    --restart "${DIND_RESTART}" \
    -e MANAGERS="${MANAGERS}" \
    -e WORKERS="${WORKERS}" \
    -e PROJECT="${PROJECT}" \
    -e DTR_REPLICAS="${DTR_REPLICAS}" \
    -e DOMAIN_NAME="${DOMAIN_NAME}" \
    -e DIND_SUBNET_PREFIX="${DIND_SUBNET_PREFIX}" \
    -e UCP_PORT="443" \
    -e KUBE_PORT="6443" \
    -e HRM_HTTP_PORT="8080" \
    -e HRM_HTTPS_PORT="8443" \
    -e INGRESS_HTTP_PORT="34080" \
    -e INGRESS_HTTPS_PORT="34443" \
    mbentley/docker-in-docker:haproxy > /dev/null

    # check to see if we should start HAProxy
    if [ "${WAS_RUNNING}" != "false" ]
    then
      echo -n "Starting ${PROJECT}-ddc-lb..."
      docker -H unix:///var/run/docker.sock start "${PROJECT}"-ddc-lb > /dev/null
      echo "done"
    fi
  echo -e "done.\\n"
}

launch_demo() {
  if [ "$(echo "${UCP_VERSION}" | awk -F '.' '{print $1}')" == "2" ]
  then
    HRM_NETWORK="ucp-hrm"
  else
    HRM_NETWORK="ucp-interlock"
  fi

  # launch Jenkins on the first manager for predictable storage
  echo "Creating Jenkins service on '${PROJECT}-docker1'..."
  docker -H tcp://127.0.0.1:1001 service create \
    --detach \
    --replicas 1 \
    --constraint "node.hostname == ${PROJECT}-docker1" \
    --env DTR_URL="dtr.${DOMAIN_NAME}" \
    --env DEMO_MASTER="$(docker -H unix:///var/run/docker.sock inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' "${PROJECT}"-docker1)" \
    --env DOMAIN_NAME="${DOMAIN_NAME}" \
    --env GITHUB_USERNAME="${GH_USERNAME}" \
    --env GIT_SERVER="http://gogs.${DOMAIN_NAME}" \
    --mount type=volume,source=jenkins-data,destination=/var/lib/jenkins,readonly=false \
    --network ${HRM_NETWORK} \
    --label "com.docker.ucp.mesh.http.8080=internal_port=8080,external_route=http://jenkins.${DOMAIN_NAME}" \
    --name jenkins \
    dockersolutions/jenkins:latest
  echo -e "done.\\n"

  # launch Gogs on the first manager for predictable storage
  echo "Creating Gogs service on '${PROJECT}-docker1'..."
  docker -H tcp://127.0.0.1:1001 service create \
    --detach \
    --replicas 1 \
    --constraint "node.hostname == ${PROJECT}-docker1" \
    --env DOMAIN_NAME="${DOMAIN_NAME}" \
    --mount type=volume,source=gogs-data,destination=/data,readonly=false \
    --network ${HRM_NETWORK} \
    --label "com.docker.ucp.mesh.http.3000=internal_port=3000,external_route=http://gogs.${DOMAIN_NAME}" \
    --name gogs \
    mbentley/solutions-gogs:latest
  echo -e "done.\\n"

  # make sure hosts file has correct entries written to it
  write_hosts
}

write_hosts() {
  # check to see if on macOS and use sed appropriately
  if [ "$(uname -s)" = "Darwin" ]
  then
    SED="sed -i ''"
  else
    SED="sed -i"
  fi

  # check for old /etc/hosts file entry and remove; preparing to add the new entry
  HOSTS_FILE="/etc/hosts"
  OLD_HOSTS_LINE="${ALIAS_IP} ucp.${DOMAIN_NAME} dtr.${DOMAIN_NAME} jenkins.${DOMAIN_NAME} gogs.${DOMAIN_NAME} docker-demo-dev.${DOMAIN_NAME} docker-demo-test.${DOMAIN_NAME} docker-demo-prd.${DOMAIN_NAME} docker-demo-dev-k8s.${DOMAIN_NAME} docker-demo-test-k8s.${DOMAIN_NAME} docker-demo-prd-k8s.${DOMAIN_NAME} ### managed by dind_ddc"
  if grep -q "${OLD_HOSTS_LINE}" "${HOSTS_FILE}"
  then
    echo -e "Removing legacy dind_ddc entry to ${HOSTS_FILE} (requires sudo)"
    #shellcheck disable=SC2086
    sudo ${SED} "/${OLD_HOSTS_LINE}/d" "${HOSTS_FILE}"
  fi

  # create entries in /etc/hosts file
  HOSTS_FILE="/etc/hosts"
  HOSTS_LINE="${ALIAS_IP} ucp.${DOMAIN_NAME} dtr.${DOMAIN_NAME} jenkins.${DOMAIN_NAME} gogs.${DOMAIN_NAME} docker-demo-dev.${DOMAIN_NAME} docker-demo-test.${DOMAIN_NAME} docker-demo-prd.${DOMAIN_NAME} docker-demo-dev-k8s.${DOMAIN_NAME} docker-demo-test-k8s.${DOMAIN_NAME} docker-demo-prd-k8s.${DOMAIN_NAME} ### managed by dind_docker_enterprise"
  if ! grep -q "${HOSTS_LINE}" "${HOSTS_FILE}"
  then
    echo -e "Adding entry to ${HOSTS_FILE} for the following DNS FQDNs (requires sudo):\\n  * ucp.${DOMAIN_NAME}\\n  * dtr.${DOMAIN_NAME}\\n  * jenkins.${DOMAIN_NAME}\\n  * gogs.${DOMAIN_NAME}\\n  * docker-demo-dev.${DOMAIN_NAME}\\n  * docker-demo-test.${DOMAIN_NAME}\\n  * docker-demo-prd.${DOMAIN_NAME}\\n  * docker-demo-dev-k8s.${DOMAIN_NAME}\\n  * docker-demo-test-k8s.${DOMAIN_NAME}\\n  * docker-demo-prd-k8s.${DOMAIN_NAME}"
    echo "${HOSTS_LINE}" | sudo tee -a "${HOSTS_FILE}" > /dev/null
  else
    echo "Hosts file entry already exists; skipping..."
  fi
  echo -e "done.\\n"
}

remove_hosts() {
  # check to see if on macOS and use sed appropriately
  if [ "$(uname -s)" = "Darwin" ]
  then
    SED="sed -i ''"
  else
    SED="sed -i"
  fi

  # remove entry if it exists
  HOSTS_FILE="/etc/hosts"
  HOSTS_LINE="${ALIAS_IP} ucp.${DOMAIN_NAME} dtr.${DOMAIN_NAME} jenkins.${DOMAIN_NAME} gogs.${DOMAIN_NAME} docker-demo-dev.${DOMAIN_NAME} docker-demo-test.${DOMAIN_NAME} docker-demo-prd.${DOMAIN_NAME} docker-demo-dev-k8s.${DOMAIN_NAME} docker-demo-test-k8s.${DOMAIN_NAME} docker-demo-prd-k8s.${DOMAIN_NAME} ### managed by dind_docker_enterprise"
  if grep -q "${HOSTS_LINE}" "${HOSTS_FILE}"
  then
    echo -e "Removing entry to ${HOSTS_FILE} for the following DNS FQDNs (requires sudo):\\n  * ucp.${DOMAIN_NAME}\\n  * dtr.${DOMAIN_NAME}\\n  * jenkins.${DOMAIN_NAME}\\n  * gogs.${DOMAIN_NAME}\\n  * docker-demo-dev.${DOMAIN_NAME}\\n  * docker-demo-test.${DOMAIN_NAME}\\n  * docker-demo-prd.${DOMAIN_NAME}\\n  * docker-demo-dev-k8s.${DOMAIN_NAME}\\n  * docker-demo-test-k8s.${DOMAIN_NAME}\\n  * docker-demo-prd-k8s.${DOMAIN_NAME}"
    #shellcheck disable=SC2086
    sudo ${SED} "/${HOSTS_LINE}/d" "${HOSTS_FILE}"
  else
    echo "Nothing to remove; skipping..."
  fi
  echo -e "done.\\n"
}

install_dtr() {
  echo -e "Preparing cluster for DTR installation...\\n"
  # validate the value for # of dtr replicas
  validate_dtr_replicas

  # check to see if an environment file was provided; if so, use that because it is more trustworth on counting the number of engines
  if [ -z "${DIND_ENV}" ]
  then
    # can't guarantee how many engines we might have; count the number of existing containers
    get_current_num_engines
  fi

  # make sure hosts file has correct entries written to it
  write_hosts

  # load images and install dtr to first replica
  ENGINE_NUM=$((MANAGERS+1))
  echo "Loading DTR images on ${PROJECT}-docker${ENGINE_NUM}..."
  docker -H tcp://127.0.0.1:100${ENGINE_NUM} load -i "${DTR_IMAGES}"

  # give the node a few seconds to wait after loading the images
  sleep 15

  echo -e "done.\\n"

  echo "Installing DTR on ${PROJECT}-docker${ENGINE_NUM}..."
  #shellcheck disable=SC2086
  docker -H tcp://127.0.0.1:100${ENGINE_NUM} run -it --rm "${DTR_REPO}":"${DTR_VERSION}" install ${DTR_OPTIONS} --ucp-url https://ucp.${DOMAIN_NAME} --ucp-username admin --ucp-password docker123 --ucp-node "${PROJECT}"-docker${ENGINE_NUM} --ucp-ca "$(docker -H unix:///var/run/docker.sock run -i --rm mbentley/curl -ks https://ucp.${DOMAIN_NAME}/ca)" --dtr-external-url "dtr.${DOMAIN_NAME}" --dtr-storage-volume /data --replica-id 0000000000e${ENGINE_NUM}
  echo -e "done.\\n"

  # load images and join additional DTR replicas
  for ((ENGINE_NUM=((MANAGERS+2)); ENGINE_NUM<=((MANAGERS+DTR_REPLICAS)); ENGINE_NUM++))
  do
    echo "Loading DTR images on ${PROJECT}-docker${ENGINE_NUM}..."
    docker -H tcp://127.0.0.1:100${ENGINE_NUM} load -i "${DTR_IMAGES}"

    # give the node a few seconds to wait after loading the images
    sleep 15

    echo -e "done.\\n"

    echo "Joining ${PROJECT}-docker${ENGINE_NUM} as a DTR replica..."
    #shellcheck disable=SC2086
    docker -H tcp://127.0.0.1:100${ENGINE_NUM} run -it --rm "${DTR_REPO}":"${DTR_VERSION}" join ${DTR_OPTIONS} --ucp-url https://ucp.${DOMAIN_NAME} --ucp-username admin --ucp-password docker123 --ucp-node "${PROJECT}"-docker${ENGINE_NUM} --ucp-ca "$(docker -H unix:///var/run/docker.sock run -i --rm mbentley/curl -ks https://ucp.${DOMAIN_NAME}/ca)" --existing-replica-id 0000000000e$((MANAGERS+1)) --replica-id 0000000000e${ENGINE_NUM}
    echo -e "done.\\n"
  done

  echo -n "Waiting for DTR to be ready..."
  #shellcheck disable=SC2016
  docker -H unix:///var/run/docker.sock run -i --rm -e DOMAIN_NAME="${DOMAIN_NAME}" --entrypoint sh mbentley/curl -c 'while [ "$(curl -sk -o /dev/null -w "%{http_code}" "https://dtr.${DOMAIN_NAME}/health")" -ne "200" ]; do   echo -n ".";   sleep 1; done'
  echo -e "done.\\n\\n"

  # check for jq
  if hash jq 2>/dev/null
  then
    echo -e "'jq' found; using native binary\\n"
    JQ="jq"
  else
    echo -e "'jq' not found; using Docker image mbentley/jq\\n"
    JQ="docker -H unix:///var/run/docker.sock run -i --rm mbentley/jq"
  fi

  echo -n "Disabling metrics..."
  DISABLE_METRICS="$(docker -H unix:///var/run/docker.sock run -i --rm mbentley/curl -sk -X POST -u admin:docker123 --header "Content-Type: application/json" --header "Accept: application/json" -d '{"anonymizeAnalytics":false,"reportAnalytics":false}' "https://dtr.${DOMAIN_NAME}/api/v0/meta/settings" | ${JQ} .reportAnalytics 2>/dev/null)"
  if [ "${DISABLE_METRICS}" = "false" ]
  then
    echo -e "done.\\n\\n"
  else
    echo -e "error disabling metrics.\\n\\n"
  fi

  echo -e "DTR installation complete.\\n"
}

install_summary_swarm() {
  # Swarm
  echo -e "Swarm mode cluster ready:"
  docker -H tcp://127.0.0.1:1001 node ls
  #shellcheck disable=SC2016
  echo -e "\\nTo connect to the engine/Swarm, use:\\neval "'"$('"${SCRIPT_PATH}"' connect_engine 1)"'
}

install_summary_engines() {
  # Swarm
  echo -e "Docker Engines ready:"
  project_status
  #shellcheck disable=SC2016
  echo -e "\\nTo connect to the engines, use:\\neval "'"$('"${SCRIPT_PATH}"' connect_engine 1)"'
}

install_summary_haproxy() {
  # HAProxy
  echo -e "The HAProxy stats page should now be available at http://${ALIAS_IP}/haproxy?stats"
}

install_summary_ucp() {
  # UCP
  echo -e "UCP should now be available at https://ucp.${DOMAIN_NAME}/"
  echo -e "  Username: admin\\tPassword: docker123"
}

install_summary_dtr() {
  # DTR
  echo -e "DTR should now be available at https://dtr.${DOMAIN_NAME}/"
  echo -e "  Username: admin\\tPassword: docker123"
}

launch_summary_demo() {
  # Jenkins
  echo -e "Jenkins should now be available at http://jenkins.${DOMAIN_NAME}/ once HRM/Interlock picks up the configuration"
  echo -e "  Username: demo\\tPassword: docker123"
  echo -e "  To initialize the Jenkins environment, execute the util > _initialize-demo-env job\\n"

  # Gogs
  echo -e "Gogs should now be available at http://gogs.${DOMAIN_NAME}/ once HRM/Interlock picks up the configuration"
  echo -e "  Username: demo\\tPassword: docker123\\n"
  echo -e "  Jenkins will have pushed the initial data into the repo using the _initialize-demo-env job.\\n"
  echo -e "  Add a git remote using:\\n    git remote add gogs http://gogs.${DOMAIN_NAME}/demo/docker-demo.git\\n"
  echo -e "  Then you will be able to push using:\\n    git push gogs <branch>"
}

destroy_swarm() {
  echo "Warning: This will destroy any containers and data associated with the project ${PROJECT}"
  read -r -p "Would you like to continue? [y/N] " RESPONSE
  case "$RESPONSE" in
    [yY][eE][sS]|[yY])
      # continue
      ;;
    [nN][oO]|[nN])
      echo "Aborting..."
      exit 1
      ;;
    *)
      echo "Invalid input; aborting..."
      exit 1
      ;;
  esac

  CONTAINERS="$(get_container_list)"

  if [ -z "${CONTAINERS}" ]
  then
    echo -e "\\nNo project containers to kill; skipping..."
  else
    echo -e "\\nKilling project containers..."
    #shellcheck disable=SC2086
    docker -H unix:///var/run/docker.sock kill ${CONTAINERS} || true
  fi
  echo -e "done.\\n"

  if [ -z "${CONTAINERS}" ]
  then
    echo "No project containers to remove; skipping..."
  else
    echo "Removing project containers..."
    #shellcheck disable=SC2086
    docker -H unix:///var/run/docker.sock rm ${CONTAINERS}
  fi
  echo -e "done.\\n"

  VOLUMES="$(get_volume_list)"
  if [ -z "${VOLUMES}" ]
  then
    echo "No project volumes to remove; skipping..."
  else
    echo "Removing persistent data for Docker engines..."
    #shellcheck disable=SC2086
    docker -H unix:///var/run/docker.sock volume rm ${VOLUMES}
  fi
  echo -e "done.\\n"

  VOLUMES="$(docker volume ls -q --filter name=shared-mirror-cache)"
  if [ -z "${VOLUMES}" ]
  then
    echo "No shared volumes to remove; skipping..."
  else
    # check to see if containers are using the volume
    SHARED_CONTAINERS="$(docker -H unix:///var/run/docker.sock ps -a --format '{{.Names}}' --filter=volume=shared-mirror-cache | tr '\\n' ' ' | sed 's/ *$//')"
    if [ -z "${SHARED_CONTAINERS}" ]
    then
      echo "Removing shared persistent data for Docker engines..."
      #shellcheck disable=SC2086
      docker -H unix:///var/run/docker.sock volume rm ${VOLUMES}
    else
      echo "Shared data volume is being used by other containers (${SHARED_CONTAINERS}); skipping removal..."
    fi
  fi
  echo -e "done.\\n"

  NETWORKS="$(get_network_list)"
  if [ -z "${NETWORKS}" ]
  then
    echo "No project networks to remove; skipping..."
  else
    echo "Removing '${PROJECT}-dind' network..."
    #shellcheck disable=SC2086
    docker -H unix:///var/run/docker.sock network rm ${NETWORKS}
  fi
  echo -e "done.\\n"

  # check to see if other project still exist
  if [ "$(check_other_projects)" -eq "0" ]
  then
    remove_net_alias
    remove_hosts
  else
    echo -e "Skipping removal of network alias and hosts file entries; other projects still exist\\ndone."
  fi
}

pull_images() {
  echo "Pulling mbentley/docker-in-docker:haproxy..."
  docker pull mbentley/docker-in-docker:haproxy
  echo -e "done.\\n"

  echo "Pulling mbentley/docker-in-docker:${DIND_TAG}..."
  docker pull mbentley/docker-in-docker:"${DIND_TAG}"
  echo -e "done.\\n"
}

check_subnet() {
  for i in $(docker -H unix:///var/run/docker.sock network ls -q)
  do
    if [ "$(docker -H unix:///var/run/docker.sock network inspect --format '{{range .IPAM.Config}}{{.Subnet}}{{end}}' "${i}")" = "${DIND_SUBNET}" ]
    then
      echo "ERROR: the subnet specified (${DIND_SUBNET}) for the '${PROJECT}-dind' network conflicts with the existing network '$(docker -H unix:///var/run/docker.sock network inspect --format '{{.Name}}' "${i}")'"
      echo "Use DIND_SUBNET to specify a different subnet when launching a new environment"
      exit 1
    fi
  done

  echo "Subnet (${DIND_SUBNET}) is available."
}

create_network() {
  NETWORKS="$(get_network_list)"
  if [ -z "${NETWORKS}" ]
  then
    echo "Creating '${PROJECT}-dind' network with the subnet ${DIND_SUBNET}..."
    docker -H unix:///var/run/docker.sock network create --driver bridge --label project="${PROJECT}" --subnet="${DIND_SUBNET}" "${PROJECT}"-dind
    echo -e "done.\\n"
  else
    echo -e "Network '${PROJECT}-dind' already exists; skipping creation...\\ndone.\\n"
  fi
}

main() {
  case ${1}:${2} in
    launch:all|create_all:*)
      initialize
      check_total_memory
      ddc_check_license
      ucp_check_tar
      dtr_check_tar
      validate_dtr_replicas
      create_net_alias
      create_swarm
      install_ucp
      install_dtr
      launch_demo
      install_summary_swarm; echo
      install_summary_haproxy; echo
      install_summary_ucp; echo
      install_summary_dtr; echo
      launch_summary_demo
      ;;
    launch:ee|install_ee:*)
      initialize
      check_total_memory
      ddc_check_license
      ucp_check_tar
      dtr_check_tar
      validate_dtr_replicas
      create_net_alias
      create_swarm
      install_ucp
      install_dtr
      install_summary_swarm; echo
      install_summary_haproxy; echo
      install_summary_ucp; echo
      install_summary_dtr; echo
      ;;
    launch:demo|launch_demo:*)
      initialize
      launch_demo
      launch_summary_demo
      ;;
    launch:ucp|install_ucp:*)
      initialize
      check_total_memory
      ddc_check_license
      ucp_check_tar
      install_ucp
      install_summary_ucp
      ;;
    launch:dtr|install_dtr:*)
      initialize
      check_total_memory
      dtr_check_tar
      install_dtr
      install_summary_dtr
      ;;
    launch:swarm|create_swarm:*)
      initialize
      check_total_memory
      create_swarm
      install_summary_swarm
      ;;
    launch:engines)
      initialize
      check_total_memory
      launch_engines engineonly
      install_summary_engines
      ;;
    launch:haproxy)
      initialize
      create_net_alias
      write_hosts
      launch_haproxy
      ;;
    launch:*)
      echo -e "Usage: ${SCRIPT_PATH} launch {all|swarm|ee|ucp|dtr|demo|help}"
      echo -e "\\nCommands:"
      echo -e "  all\\t\\tlaunch a 3 node Swarm mode cluster (1 manager 2 workers), UCP, DTR, Jenkins, and Gogs"
      echo -e "  swarm\\t\\tlaunch 3 node Swarm mode cluster; 1 manager and 2 workers"
      echo -e "  engines\\tlaunch 3 nodes as stand alone Docker engines"
      echo -e "  ee\\t\\tlaunch a 3 node Swarm mode cluster (1 manager 2 workers), UCP, and DTR"
      echo -e "  ucp\\t\\tlaunch UCP (only use if a Swarm mode cluster is already launched)"
      echo -e "  dtr\\t\\tlaunch DTR on the first worker (only use if UCP is already launched)"
      echo -e "  demo\\t\\tlaunch Jenkins and Gogs (only use if you've launched UCP and DTR)"
      exit 1
      ;;
    env:start|start:*)
      initialize
      start_containers
      recreate_net_alias
      ;;
    env:stop|stop:*)
      initialize
      stop_containers
      ;;
    env:pause|pause:*)
      initialize
      pause_containers
      ;;
    env:unpause|unpause:*)
      initialize
      unpause_containers
      recreate_net_alias
      ;;
    env:recycle|recycle:*)
      initialize
      recycle_containers
      ;;
    env:destroy|destroy:*|destroy_swarm:*)
      initialize
      destroy_swarm
      ;;
    env:pull)
      initialize
      pull_images
      ;;
    env:status)
      initialize
      project_status "${3}"
      ;;
    status:*)
      initialize
      project_status "${2}"
      ;;
    env:info|env_info:*)
      initialize
      env_info
      ;;
    env:mem)
      initialize
      check_total_memory
      ;;
    env:*)
      echo -e "Usage: ${SCRIPT_PATH} env {start|stop|pause|unpause|recycle|destroy|pull|status|info|help}"
      echo -e "\\nCommands:"
      echo -e "  start\\t\\tstart ddc-lb, docker1, docker2, and docker3 daemon containers"
      echo -e "  stop\\t\\tstop ddc-lb, docker1, docker2, and docker3 daemon containers"
      echo -e "  pause\\t\\tpause ddc-lb, docker1, docker2, and docker3 daemon containers"
      echo -e "  unpause\\tunpause ddc-lb, docker1, docker2, and docker3 daemon containers"
      echo -e "  recycle\\tstop, remove, and re-create the Docker engines and 'dind' network, keeping persistent data"
      echo -e "  destroy\\tremove Swarm, the engines, and all persistent data"
      echo -e "  pull\\t\\tpull latest Docker images for current environment"
      echo -e "  status\\tdisplay environment status"
      echo -e "  info\\t\\tdisplay enviroment variable overrides currently set"
      exit 1
      ;;
    create_tar:all)
      initialize
      ucp_create_tar
      dtr_create_tar
      ;;
    create_tar:ucp|ucp_create_tar:*)
      initialize
      ucp_create_tar
      ;;
    create_tar:dtr|dtr_create_tar:*)
      initialize
      dtr_create_tar
      ;;
    create_tar:*)
      echo -e "Usage: ${SCRIPT_PATH} create_tar {all|ucp|dtr|help}"
      echo -e "\\nCommands:"
      echo -e "  all\\tcreate tarball of the UCP and DTR images"
      echo -e "  ucp\\tcreate tarball of the UCP images"
      echo -e "  dtr\\tcreate tarball of the DTR images"
      exit 1
      ;;
    net_alias:create|create_net_alias:*)
      initialize
      create_net_alias
      ;;
    net_alias:remove|remove_net_alias:*)
      initialize
      remove_net_alias
      ;;
    net_alias:recreate|recreate_net_alias:*)
      initialize
      recreate_net_alias
      ;;
    net_alias:*)
      echo -e "Usage: ${SCRIPT_PATH} net_alias {create|remove|recreate|help}"
      echo -e "\\nCommands:"
      echo -e "  create\\tcreate a network alias used for keeping a persistent IP no matter when you are (only for D4M)"
      echo -e "  remove\\tremove network alias (only for D4M)"
      echo -e "  recreate\\tre-create network alias (only for D4M)"
      exit 1
      ;;
    hosts:write)
      initialize
      write_hosts
      ;;
    hosts:remove)
      initialize
      remove_hosts
      ;;
    hosts:*)
      echo -e "Usage: ${SCRIPT_PATH} hosts {write|remove|help}"
      echo -e "\\nCommands:"
      echo -e "  write\\t\\twrite entries to hosts file"
      echo -e "  remove\\tremove entries from hosts file"
      exit 1
      ;;
    connect_engine:*)
      if [ -z "${2}" ] || [ "${2}" = "help" ]
      then
        #shellcheck disable=SC2016
        echo 'Usage: eval "$('"${SCRIPT_PATH}"' connect_engine n)"'
        if [ "${2}" = "help" ]
        then
          echo -e "\\nCommands:"
          echo -e "  n\\twhere 'n' is the engine number to connect to; sets 'DOCKER*' environment variables"
        fi
        exit 1
      else
        connect_engine "${2}"
      fi
      ;;
    *:*)
      echo "Usage: ${SCRIPT_PATH} {launch|env|create_tar|net_alias|connect_engine|help}"
      echo -e "\\nCommands:"
      echo "  ${SCRIPT_PATH} launch {all|swarm|engines|ee|ucp|dtr|demo|help}"
      echo "  ${SCRIPT_PATH} env {start|stop|pause|unpause|recycle|destroy|status|info|help}"
      echo "  ${SCRIPT_PATH} create_tar {all|ucp|dtr|help}"
      echo "  ${SCRIPT_PATH} net_alias {create|remove|recreate|help}"
      echo "  ${SCRIPT_PATH} connect_engine {n|help}"
      exit 1
      ;;
  esac
}

main "${@}"
